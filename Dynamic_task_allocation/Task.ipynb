{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import apply_features\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    features = {word: (word in tokens) for word in words}\n",
    "    return features\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    filtered_token = [x for x in filtered_tokens if x not in [',','.','\\'']]\n",
    "    # print(f\"Filtered Token: {filtered_tokens}\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_token]\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    # print(f\"Lemmatized text: {lemmatized_tokens}\")\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dummy_data import shift_log_data, workers_data, training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_training_data = [preprocess_text(text) for text, _ in training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['issue',\n",
       " 'work completed',\n",
       " 'routine inspection completed without issue',\n",
       " 'minor delay shovel operation',\n",
       " 'overburden removal delay due weather',\n",
       " 'delay material supply',\n",
       " 'work delayed due unforeseen circumstance',\n",
       " 'drill malfunction',\n",
       " 'blasting equipment issue ; delay obd removal',\n",
       " 'drill performance issue',\n",
       " 'unexpected machinery breakdown',\n",
       " 'faulty conveyor belt',\n",
       " 'routine maintenance',\n",
       " 'maintenance scheduling conflict',\n",
       " 'power outage affecting operation',\n",
       " 'overtime work due shift handover delay',\n",
       " 'unexpected increase workload',\n",
       " 'supervisor late 12 hour',\n",
       " 'insufficient raw material',\n",
       " 'delayed delivery spare part',\n",
       " 'inadequate stock essential supply',\n",
       " 'shortage critical resource',\n",
       " 'operator error causing delay',\n",
       " 'incorrectly set machine parameter',\n",
       " 'employee absence causing delay',\n",
       " 'mistake task execution',\n",
       " 'safety protocol breach',\n",
       " 'emergency evacuation drill conducted',\n",
       " 'safety gear available',\n",
       " 'safety hazard identified workplace']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blasting equipment issue issue machine chain engine machine'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(text='Blasting equipment issue, issue in the machine chains and the engine of the machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(word for sentence in process_training_data for word in word_tokenize(sentence.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conducted': False,\n",
       " 'critical': False,\n",
       " 'overburden': False,\n",
       " 'supply': False,\n",
       " 'conflict': False,\n",
       " 'causing': False,\n",
       " 'material': False,\n",
       " 'due': False,\n",
       " 'unforeseen': False,\n",
       " 'inspection': False,\n",
       " 'shift': False,\n",
       " 'without': False,\n",
       " 'incorrectly': False,\n",
       " 'operator': False,\n",
       " 'equipment': False,\n",
       " 'faulty': False,\n",
       " 'workplace': False,\n",
       " 'malfunction': True,\n",
       " 'machinery': False,\n",
       " 'inadequate': False,\n",
       " 'hazard': False,\n",
       " 'handover': False,\n",
       " 'absence': False,\n",
       " 'stock': False,\n",
       " 'removal': True,\n",
       " 'late': False,\n",
       " 'error': False,\n",
       " 'conveyor': False,\n",
       " 'completed': False,\n",
       " 'delivery': False,\n",
       " 'routine': False,\n",
       " 'employee': False,\n",
       " 'essential': False,\n",
       " 'mistake': False,\n",
       " 'shortage': False,\n",
       " 'delayed': False,\n",
       " 'workload': False,\n",
       " 'resource': False,\n",
       " 'machine': True,\n",
       " 'power': False,\n",
       " 'performance': False,\n",
       " 'available': False,\n",
       " 'gear': False,\n",
       " 'overtime': False,\n",
       " 'emergency': False,\n",
       " 'drill': False,\n",
       " 'unexpected': False,\n",
       " 'parameter': False,\n",
       " 'increase': False,\n",
       " ';': False,\n",
       " 'spare': False,\n",
       " 'task': False,\n",
       " 'execution': False,\n",
       " 'minor': False,\n",
       " 'weather': False,\n",
       " 'supervisor': False,\n",
       " 'part': False,\n",
       " 'belt': False,\n",
       " 'obd': True,\n",
       " 'insufficient': False,\n",
       " 'delay': False,\n",
       " 'scheduling': False,\n",
       " 'operation': False,\n",
       " 'work': False,\n",
       " 'evacuation': False,\n",
       " 'maintenance': False,\n",
       " 'breach': False,\n",
       " 'hour': False,\n",
       " 'circumstance': False,\n",
       " 'affecting': False,\n",
       " '12': False,\n",
       " 'raw': False,\n",
       " 'breakdown': False,\n",
       " 'set': False,\n",
       " 'identified': False,\n",
       " 'protocol': False,\n",
       " 'issue': False,\n",
       " 'outage': False,\n",
       " 'shovel': True,\n",
       " 'blasting': False,\n",
       " 'safety': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(text='Malfunction of the Shovel machine in the OBD removal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "def get_sentiment(text):\n",
    "    scores = sentiment_analyzer.polarity_scores(text)\n",
    "    sentiment = scores['pos']\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_issue(issue):\n",
    "    features = extract_features(issue)\n",
    "    return classifier.classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = [(extract_features(text), label) for text, label in training_data]\n",
    "classifier = NaiveBayesClassifier.train(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_issues = [data[7] for worker_id, data in shift_log_data.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue: 'No issues' classified as: Equipment Issue.\n",
      "Issue: 'Minor delay in shovel operation' classified as: Delay.\n",
      "Issue: 'Drill malfunction' classified as: Equipment Issue.\n",
      "Issue: 'Blasting equipment issue; Delay in OBD removal' classified as: Equipment Issue.\n",
      "Issue: 'No issues' classified as: Equipment Issue.\n",
      "Issue: 'All tasks completed' classified as: No Issue.\n"
     ]
    }
   ],
   "source": [
    "for issue in new_issues:\n",
    "    classification = identify_issue(issue)\n",
    "    print(f\"Issue: '{issue}' classified as: {classification}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
